{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramraj/.local/share/virtualenvs/sg-generation-6Q740Mlp/lib/python3.8/site-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_core_web_sm' (2.2.0) requires spaCy v2.2 and is incompatible with the current spaCy version (2.3.2). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.utils.data as data\n",
    "import networkx as nx\n",
    "import nltk\n",
    "import spacy\n",
    "import gensim\n",
    "import en_core_web_sm\n",
    "from nltk.data import find\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_SG_PATH = \"../VG-data/scene_graphs.json\"\n",
    "\n",
    "SRC_ANSWER_VOCAB_FILE = \"./intermediate_files/answer_vocab.txt\"\n",
    "SRC_SGQAS_OF_INTEREST_QA_DATA_FILE = \"./intermediate_files/filtered_qa_data.json\"\n",
    "\n",
    "DST_SG_FEATURES_DATA_FOLDER = \"./intermediate_files/sg_features/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_sg_data = json.load(open(SRC_SG_PATH, 'r'))\n",
    "global_qa_data = json.load(open(SRC_SGQAS_OF_INTEREST_QA_DATA_FILE, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VQAVisualGenomeDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, sg_data_path, qa_data_path, ans_vocab_data_path):\n",
    "        self.sg_data_path = sg_data_path\n",
    "        self.qa_data_path = qa_data_path\n",
    "        self.ans_vocab_data_path = ans_vocab_data_path  \n",
    "        \n",
    "        self.sample_cnt = 0\n",
    "        self.data_sgvqa = []\n",
    "        self._load_dataset()\n",
    "        \n",
    "    def _load_dataset(self):\n",
    "        print('-> Loading filtered dataset ...')\n",
    "        self.ans_vocab_data = sorted(open(self.ans_vocab_data_path, 'r').read().strip().split(\"\\n\"))\n",
    "        sg_data = global_sg_data\n",
    "        qa_data = global_qa_data\n",
    "#         sg_data = json.load(open(self.sg_data_path, 'r'))\n",
    "#         qa_data = json.load(open(self.qa_data_path, 'r'))        \n",
    "        \n",
    "        for sample_img, sample_ans in zip(sg_data, qa_data):\n",
    "            if sample_img['image_id'] != sample_ans['id']:\n",
    "                print(\"IDs did not match !\")\n",
    "                continue                \n",
    "            for qa_index, qa in enumerate(sample_ans['qas']):\n",
    "                if (qa['qas_skip']): continue\n",
    "                question = qa['question']\n",
    "                answer = qa['answer'].replace(\".\", \"\").lower()\n",
    "                # sg = sample_img                \n",
    "                self.data_sgvqa.append({\"question\": question, \"answer\": answer, \"sg\": sample_img})\n",
    "                \n",
    "                self.sample_cnt += 1\n",
    "                if (self.sample_cnt > 10): break # todo: remove                       \n",
    "        \n",
    "        print('-> Finished loading data : num. samples -> {}'.format(self.sample_cnt))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.sample_cnt\n",
    "                \n",
    "    def __getitem__(self, index):\n",
    "        if index < self.sample_cnt:\n",
    "            item = self.data_sgvqa[index]\n",
    "        else:\n",
    "            item = self.data_sgvqa[index - self.sample_cnt]\n",
    "        return item\n",
    "\n",
    "    def num_classes(self):\n",
    "        return len(self.ans_vocab_data)\n",
    "\n",
    "#     def vocab_words(self):\n",
    "#         return self.dataset_vqa.vocab_words()\n",
    "\n",
    "#     def vocab_answers(self):\n",
    "#         return self.dataset_vqa.vocab_answers()\n",
    "\n",
    "    def data_loader(self, batch_size=10, num_workers=4, shuffle=False):\n",
    "        return DataLoader(self, \n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=shuffle,\n",
    "                          num_workers=num_workers, \n",
    "                          pin_memory=True)\n",
    "\n",
    "    def split_name(self, testdev=False):\n",
    "        return self.data_sgvqa.split_name(testdev=testdev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Loading filtered dataset ...\n",
      "-> Finished loading data : num. samples -> 95751\n"
     ]
    }
   ],
   "source": [
    "vqa_dataloader = VQAVisualGenomeDataset(SRC_SG_PATH, SRC_SGQAS_OF_INTEREST_QA_DATA_FILE, SRC_ANSWER_VOCAB_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What are the men doing?',\n",
       " 'answer': 'interacting',\n",
       " 'sg': {'relationships': [{'synsets': ['along.r.01'],\n",
       "    'predicate': 'ON',\n",
       "    'relationship_id': 15927,\n",
       "    'object_id': 5046,\n",
       "    'subject_id': 5045},\n",
       "   {'synsets': ['wear.v.01'],\n",
       "    'predicate': 'wears',\n",
       "    'relationship_id': 15928,\n",
       "    'object_id': 5048,\n",
       "    'subject_id': 1058529},\n",
       "   {'synsets': ['have.v.01'],\n",
       "    'predicate': 'has',\n",
       "    'relationship_id': 15929,\n",
       "    'object_id': 5050,\n",
       "    'subject_id': 5049},\n",
       "   {'synsets': ['along.r.01'],\n",
       "    'predicate': 'ON',\n",
       "    'relationship_id': 15930,\n",
       "    'object_id': 1058508,\n",
       "    'subject_id': 1058507},\n",
       "   {'synsets': ['along.r.01'],\n",
       "    'predicate': 'ON',\n",
       "    'relationship_id': 15931,\n",
       "    'object_id': 1058534,\n",
       "    'subject_id': 5055},\n",
       "   {'synsets': ['have.v.01'],\n",
       "    'predicate': 'has',\n",
       "    'relationship_id': 15932,\n",
       "    'object_id': 1058511,\n",
       "    'subject_id': 1058529},\n",
       "   {'synsets': ['next.r.01'],\n",
       "    'predicate': 'next to',\n",
       "    'relationship_id': 15933,\n",
       "    'object_id': 1058539,\n",
       "    'subject_id': 1058534},\n",
       "   {'synsets': ['have.v.01'],\n",
       "    'predicate': 'has',\n",
       "    'relationship_id': 15934,\n",
       "    'object_id': 5060,\n",
       "    'subject_id': 1058515},\n",
       "   {'synsets': ['have.v.01'],\n",
       "    'predicate': 'has',\n",
       "    'relationship_id': 15935,\n",
       "    'object_id': 1058518,\n",
       "    'subject_id': 1058529},\n",
       "   {'synsets': ['along.r.01'],\n",
       "    'predicate': 'ON',\n",
       "    'relationship_id': 15936,\n",
       "    'object_id': 1058534,\n",
       "    'subject_id': 1058519},\n",
       "   {'synsets': ['wear.v.01'],\n",
       "    'predicate': 'wears',\n",
       "    'relationship_id': 15937,\n",
       "    'object_id': 5048,\n",
       "    'subject_id': 1058529},\n",
       "   {'synsets': ['have.v.01'],\n",
       "    'predicate': 'has',\n",
       "    'relationship_id': 15938,\n",
       "    'object_id': 1058525,\n",
       "    'subject_id': 1058532},\n",
       "   {'synsets': ['have.v.01'],\n",
       "    'predicate': 'has',\n",
       "    'relationship_id': 15939,\n",
       "    'object_id': 1058511,\n",
       "    'subject_id': 1058529},\n",
       "   {'synsets': ['wear.v.01'],\n",
       "    'predicate': 'wears',\n",
       "    'relationship_id': 15940,\n",
       "    'object_id': 1058528,\n",
       "    'subject_id': 1058529},\n",
       "   {'synsets': ['have.v.01'],\n",
       "    'predicate': 'has',\n",
       "    'relationship_id': 15941,\n",
       "    'object_id': 1058530,\n",
       "    'subject_id': 1058532},\n",
       "   {'synsets': ['have.v.01'],\n",
       "    'predicate': 'has',\n",
       "    'relationship_id': 15942,\n",
       "    'object_id': 1058531,\n",
       "    'subject_id': 1058532},\n",
       "   {'synsets': ['along.r.01'],\n",
       "    'predicate': 'parked on',\n",
       "    'relationship_id': 15943,\n",
       "    'object_id': 1058534,\n",
       "    'subject_id': 5051},\n",
       "   {'synsets': ['along.r.01'],\n",
       "    'predicate': 'parked on',\n",
       "    'relationship_id': 15944,\n",
       "    'object_id': 1058534,\n",
       "    'subject_id': 1058535},\n",
       "   {'synsets': ['along.r.01'],\n",
       "    'predicate': 'parked on',\n",
       "    'relationship_id': 15945,\n",
       "    'object_id': 1058539,\n",
       "    'subject_id': 1058536},\n",
       "   {'synsets': ['along.r.01'],\n",
       "    'predicate': 'parked on',\n",
       "    'relationship_id': 15946,\n",
       "    'object_id': 1058539,\n",
       "    'subject_id': 1058515},\n",
       "   {'synsets': ['along.r.01'],\n",
       "    'predicate': 'ON',\n",
       "    'relationship_id': 4265923,\n",
       "    'object_id': 3798575,\n",
       "    'subject_id': 1058535},\n",
       "   {'synsets': ['behind.r.01'],\n",
       "    'predicate': 'behind',\n",
       "    'relationship_id': 3186256,\n",
       "    'object_id': 1058532,\n",
       "    'subject_id': 1058519},\n",
       "   {'synsets': ['have.v.01'],\n",
       "    'predicate': 'holding',\n",
       "    'relationship_id': 3186257,\n",
       "    'object_id': 1058541,\n",
       "    'subject_id': 1058540},\n",
       "   {'synsets': ['wear.v.01'],\n",
       "    'predicate': 'WEARING',\n",
       "    'relationship_id': 3186258,\n",
       "    'object_id': 1058511,\n",
       "    'subject_id': 1058529},\n",
       "   {'synsets': ['have.v.01'],\n",
       "    'predicate': 'holding',\n",
       "    'relationship_id': 3186259,\n",
       "    'object_id': 1058541,\n",
       "    'subject_id': 1058532},\n",
       "   {'synsets': ['about.r.07'],\n",
       "    'predicate': 'near',\n",
       "    'relationship_id': 3186260,\n",
       "    'object_id': 1058545,\n",
       "    'subject_id': 1058544},\n",
       "   {'synsets': ['wear.v.01'],\n",
       "    'predicate': 'WEARING',\n",
       "    'relationship_id': 3186261,\n",
       "    'object_id': 1058525,\n",
       "    'subject_id': 1058532},\n",
       "   {'synsets': ['about.r.07'],\n",
       "    'predicate': 'near',\n",
       "    'relationship_id': 3186262,\n",
       "    'object_id': 1058545,\n",
       "    'subject_id': 1058544},\n",
       "   {'synsets': ['along.r.01'],\n",
       "    'predicate': 'ON',\n",
       "    'relationship_id': 3186263,\n",
       "    'object_id': 1058529,\n",
       "    'subject_id': 1058511},\n",
       "   {'synsets': ['have.v.01'],\n",
       "    'predicate': 'holding',\n",
       "    'relationship_id': 4265924,\n",
       "    'object_id': 1058541,\n",
       "    'subject_id': 3798576},\n",
       "   {'synsets': ['wear.v.01'],\n",
       "    'predicate': 'WEARING',\n",
       "    'relationship_id': 4265925,\n",
       "    'object_id': 1058518,\n",
       "    'subject_id': 3798577},\n",
       "   {'synsets': ['along.r.01'],\n",
       "    'predicate': 'along',\n",
       "    'relationship_id': 4265926,\n",
       "    'object_id': 3798578,\n",
       "    'subject_id': 1058548},\n",
       "   {'synsets': ['in.r.01'],\n",
       "    'predicate': 'IN',\n",
       "    'relationship_id': 3186264,\n",
       "    'object_id': 1058511,\n",
       "    'subject_id': 1058529},\n",
       "   {'synsets': ['wear.v.01'],\n",
       "    'predicate': 'WEARING',\n",
       "    'relationship_id': 3186265,\n",
       "    'object_id': 1058528,\n",
       "    'subject_id': 1058529},\n",
       "   {'synsets': ['along.r.01'],\n",
       "    'predicate': 'on top of',\n",
       "    'relationship_id': 3186266,\n",
       "    'object_id': 1058539,\n",
       "    'subject_id': 1058519},\n",
       "   {'synsets': ['next.r.01'],\n",
       "    'predicate': 'next to',\n",
       "    'relationship_id': 3186267,\n",
       "    'object_id': 1058539,\n",
       "    'subject_id': 1058545},\n",
       "   {'synsets': ['wear.v.01'],\n",
       "    'predicate': 'WEARING',\n",
       "    'relationship_id': 3186268,\n",
       "    'object_id': 1058518,\n",
       "    'subject_id': 1058529},\n",
       "   {'synsets': ['behind.r.01'],\n",
       "    'predicate': 'behind',\n",
       "    'relationship_id': 3186269,\n",
       "    'object_id': 1058529,\n",
       "    'subject_id': 1058544},\n",
       "   {'synsets': ['by.r.01'],\n",
       "    'predicate': 'by',\n",
       "    'relationship_id': 3186270,\n",
       "    'object_id': 1058534,\n",
       "    'subject_id': 1058549},\n",
       "   {'synsets': ['wear.v.01'],\n",
       "    'predicate': 'WEARING',\n",
       "    'relationship_id': 3186271,\n",
       "    'object_id': 1058530,\n",
       "    'subject_id': 1058532},\n",
       "   {'synsets': [],\n",
       "    'predicate': 'with',\n",
       "    'relationship_id': 4265927,\n",
       "    'object_id': 3798579,\n",
       "    'subject_id': 1058508}],\n",
       "  'image_id': 1,\n",
       "  'objects': [{'synsets': ['clock.n.01'],\n",
       "    'h': 339,\n",
       "    'object_id': 1058498,\n",
       "    'names': ['clock'],\n",
       "    'w': 79,\n",
       "    'attributes': ['green', 'tall'],\n",
       "    'y': 91,\n",
       "    'x': 421},\n",
       "   {'synsets': ['street.n.01'],\n",
       "    'h': 262,\n",
       "    'object_id': 5046,\n",
       "    'names': ['street'],\n",
       "    'w': 714,\n",
       "    'attributes': ['sidewalk'],\n",
       "    'y': 328,\n",
       "    'x': 77},\n",
       "   {'synsets': ['shade.n.01'],\n",
       "    'h': 192,\n",
       "    'object_id': 5045,\n",
       "    'names': ['shade'],\n",
       "    'w': 274,\n",
       "    'y': 338,\n",
       "    'x': 119},\n",
       "   {'synsets': ['man.n.01'],\n",
       "    'h': 262,\n",
       "    'object_id': 1058529,\n",
       "    'names': ['man'],\n",
       "    'w': 60,\n",
       "    'y': 249,\n",
       "    'x': 238},\n",
       "   {'synsets': ['gym_shoe.n.01'],\n",
       "    'h': 26,\n",
       "    'object_id': 5048,\n",
       "    'names': ['sneakers'],\n",
       "    'w': 52,\n",
       "    'attributes': ['grey'],\n",
       "    'y': 489,\n",
       "    'x': 243},\n",
       "   {'synsets': ['headlight.n.01'],\n",
       "    'h': 15,\n",
       "    'object_id': 5050,\n",
       "    'names': ['headlight'],\n",
       "    'w': 23,\n",
       "    'attributes': ['off'],\n",
       "    'y': 366,\n",
       "    'x': 514},\n",
       "   {'synsets': ['car.n.01'],\n",
       "    'h': 98,\n",
       "    'object_id': 5049,\n",
       "    'names': ['car'],\n",
       "    'w': 74,\n",
       "    'y': 315,\n",
       "    'x': 479},\n",
       "   {'synsets': ['bicycle.n.01'],\n",
       "    'h': 34,\n",
       "    'object_id': 5051,\n",
       "    'names': ['bike'],\n",
       "    'w': 28,\n",
       "    'attributes': ['parked', 'far away'],\n",
       "    'y': 319,\n",
       "    'x': 318},\n",
       "   {'synsets': ['bicycle.n.01'],\n",
       "    'h': 35,\n",
       "    'object_id': 1058535,\n",
       "    'names': ['bike'],\n",
       "    'w': 29,\n",
       "    'attributes': ['parked', 'far away', 'chained'],\n",
       "    'y': 319,\n",
       "    'x': 334},\n",
       "   {'synsets': ['sign.n.02'],\n",
       "    'h': 182,\n",
       "    'object_id': 1058507,\n",
       "    'names': ['sign'],\n",
       "    'w': 88,\n",
       "    'attributes': ['black'],\n",
       "    'y': 13,\n",
       "    'x': 118},\n",
       "   {'synsets': ['building.n.01'],\n",
       "    'h': 536,\n",
       "    'object_id': 1058508,\n",
       "    'names': ['building'],\n",
       "    'w': 218,\n",
       "    'attributes': ['tall', 'brick', 'made of bricks'],\n",
       "    'y': 2,\n",
       "    'x': 1},\n",
       "   {'synsets': ['trunk.n.01'],\n",
       "    'h': 327,\n",
       "    'object_id': 5055,\n",
       "    'names': ['tree trunk'],\n",
       "    'w': 87,\n",
       "    'y': 234,\n",
       "    'x': 622},\n",
       "   {'synsets': ['sidewalk.n.01'],\n",
       "    'h': 266,\n",
       "    'object_id': 1058534,\n",
       "    'names': ['sidewalk'],\n",
       "    'w': 722,\n",
       "    'attributes': ['brick'],\n",
       "    'y': 331,\n",
       "    'x': 77},\n",
       "   {'synsets': ['shirt.n.01'],\n",
       "    'h': 101,\n",
       "    'object_id': 1058511,\n",
       "    'names': ['shirt'],\n",
       "    'w': 59,\n",
       "    'attributes': ['red', 'orange'],\n",
       "    'y': 289,\n",
       "    'x': 241},\n",
       "   {'synsets': ['street.n.01'],\n",
       "    'h': 233,\n",
       "    'object_id': 1058539,\n",
       "    'names': ['street'],\n",
       "    'w': 440,\n",
       "    'attributes': ['clean'],\n",
       "    'y': 283,\n",
       "    'x': 358},\n",
       "   {'synsets': ['car.n.01'],\n",
       "    'h': 174,\n",
       "    'object_id': 1058515,\n",
       "    'names': ['car'],\n",
       "    'w': 91,\n",
       "    'attributes': ['white', 'parked'],\n",
       "    'y': 342,\n",
       "    'x': 708},\n",
       "   {'synsets': ['back.n.01'],\n",
       "    'h': 170,\n",
       "    'object_id': 5060,\n",
       "    'names': ['back'],\n",
       "    'w': 67,\n",
       "    'y': 339,\n",
       "    'x': 721},\n",
       "   {'synsets': ['spectacles.n.01'],\n",
       "    'h': 12,\n",
       "    'object_id': 1058518,\n",
       "    'names': ['glasses'],\n",
       "    'w': 20,\n",
       "    'y': 268,\n",
       "    'x': 271},\n",
       "   {'synsets': ['parking_meter.n.01'],\n",
       "    'h': 143,\n",
       "    'object_id': 1058519,\n",
       "    'names': ['parking meter'],\n",
       "    'w': 32,\n",
       "    'attributes': ['orange'],\n",
       "    'y': 327,\n",
       "    'x': 574},\n",
       "   {'synsets': ['shoe.n.01'],\n",
       "    'h': 34,\n",
       "    'object_id': 1058525,\n",
       "    'names': ['shoes'],\n",
       "    'w': 46,\n",
       "    'attributes': ['brown'],\n",
       "    'y': 481,\n",
       "    'x': 391},\n",
       "   {'synsets': ['man.n.01'],\n",
       "    'h': 251,\n",
       "    'object_id': 1058532,\n",
       "    'names': ['man'],\n",
       "    'w': 75,\n",
       "    'y': 264,\n",
       "    'x': 372},\n",
       "   {'synsets': ['trouser.n.01'],\n",
       "    'h': 118,\n",
       "    'object_id': 1058528,\n",
       "    'names': ['pants'],\n",
       "    'w': 38,\n",
       "    'attributes': ['black'],\n",
       "    'y': 384,\n",
       "    'x': 245},\n",
       "   {'synsets': ['jacket.n.01'],\n",
       "    'h': 97,\n",
       "    'object_id': 1058530,\n",
       "    'names': ['jacket'],\n",
       "    'w': 89,\n",
       "    'attributes': ['gray', 'grey'],\n",
       "    'y': 296,\n",
       "    'x': 356},\n",
       "   {'synsets': ['trouser.n.01'],\n",
       "    'h': 128,\n",
       "    'object_id': 1058531,\n",
       "    'names': ['pants'],\n",
       "    'w': 54,\n",
       "    'attributes': ['gray', 'grey'],\n",
       "    'y': 369,\n",
       "    'x': 382},\n",
       "   {'synsets': [],\n",
       "    'h': 185,\n",
       "    'object_id': 1058536,\n",
       "    'names': ['work truck'],\n",
       "    'w': 265,\n",
       "    'attributes': ['white'],\n",
       "    'y': 271,\n",
       "    'x': 521},\n",
       "   {'synsets': ['sidewalk.n.01'],\n",
       "    'h': 189,\n",
       "    'object_id': 3798575,\n",
       "    'names': ['sidewalk'],\n",
       "    'w': 50,\n",
       "    'y': 318,\n",
       "    'x': 343},\n",
       "   {'synsets': ['chin.n.01'],\n",
       "    'h': 9,\n",
       "    'object_id': 1058541,\n",
       "    'names': ['chin'],\n",
       "    'w': 11,\n",
       "    'attributes': ['raised'],\n",
       "    'y': 288,\n",
       "    'x': 399},\n",
       "   {'synsets': ['guy.n.01'],\n",
       "    'h': 250,\n",
       "    'object_id': 1058540,\n",
       "    'names': ['guy'],\n",
       "    'w': 82,\n",
       "    'y': 264,\n",
       "    'x': 369},\n",
       "   {'synsets': ['van.n.05'],\n",
       "    'h': 134,\n",
       "    'object_id': 1058542,\n",
       "    'names': ['van'],\n",
       "    'w': 233,\n",
       "    'attributes': ['parked', 'white'],\n",
       "    'y': 298,\n",
       "    'x': 529},\n",
       "   {'synsets': ['wall.n.01'],\n",
       "    'h': 533,\n",
       "    'object_id': 1058543,\n",
       "    'names': ['wall'],\n",
       "    'w': 134,\n",
       "    'attributes': ['grey'],\n",
       "    'y': 1,\n",
       "    'x': 0},\n",
       "   {'synsets': ['tree.n.01'],\n",
       "    'h': 360,\n",
       "    'object_id': 1058545,\n",
       "    'names': ['tree'],\n",
       "    'w': 176,\n",
       "    'y': 0,\n",
       "    'x': 249},\n",
       "   {'synsets': ['bicycle.n.01'],\n",
       "    'h': 35,\n",
       "    'object_id': 1058544,\n",
       "    'names': ['bikes'],\n",
       "    'w': 40,\n",
       "    'y': 319,\n",
       "    'x': 321},\n",
       "   {'synsets': ['arm.n.01'],\n",
       "    'h': 43,\n",
       "    'object_id': 1058546,\n",
       "    'names': ['arm'],\n",
       "    'w': 32,\n",
       "    'attributes': ['raised'],\n",
       "    'y': 283,\n",
       "    'x': 368},\n",
       "   {'synsets': ['shirt.n.01'],\n",
       "    'h': 66,\n",
       "    'object_id': 1058547,\n",
       "    'names': ['shirt'],\n",
       "    'w': 37,\n",
       "    'attributes': ['grey'],\n",
       "    'y': 306,\n",
       "    'x': 384},\n",
       "   {'synsets': ['man.n.01'],\n",
       "    'h': 248,\n",
       "    'object_id': 3798576,\n",
       "    'names': ['man'],\n",
       "    'w': 97,\n",
       "    'y': 264,\n",
       "    'x': 362},\n",
       "   {'synsets': ['man.n.01'],\n",
       "    'h': 264,\n",
       "    'object_id': 3798577,\n",
       "    'names': ['man'],\n",
       "    'w': 72,\n",
       "    'y': 251,\n",
       "    'x': 230},\n",
       "   {'synsets': ['road.n.01'],\n",
       "    'h': 218,\n",
       "    'object_id': 3798578,\n",
       "    'names': ['road'],\n",
       "    'w': 340,\n",
       "    'y': 295,\n",
       "    'x': 435},\n",
       "   {'synsets': [],\n",
       "    'h': 430,\n",
       "    'object_id': 1058548,\n",
       "    'names': ['lamp post'],\n",
       "    'w': 41,\n",
       "    'y': 63,\n",
       "    'x': 537},\n",
       "   {'synsets': ['tree.n.01'],\n",
       "    'h': 557,\n",
       "    'object_id': 1058549,\n",
       "    'names': ['trees'],\n",
       "    'w': 606,\n",
       "    'attributes': ['sparse'],\n",
       "    'y': 0,\n",
       "    'x': 190},\n",
       "   {'synsets': ['window.n.01'],\n",
       "    'h': 148,\n",
       "    'object_id': 3798579,\n",
       "    'names': ['windows'],\n",
       "    'w': 173,\n",
       "    'y': 4,\n",
       "    'x': 602}]}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vqa_dataloader.__getitem__(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Dataset for GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csgraph\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "\n",
    "\n",
    "def normalize(mx):\n",
    "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    mx = r_mat_inv.dot(mx)\n",
    "    \n",
    "def normalize_adj(mx):\n",
    "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "    r_inv_sqrt[np.isinf(r_inv_sqrt)] = 0.\n",
    "    r_mat_inv_sqrt = sp.diags(r_inv_sqrt)\n",
    "\n",
    "    return mx.dot(r_mat_inv_sqrt).transpose().dot(r_mat_inv_sqrt).tocoo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VQAVGSimpleDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, sg_data_path, qa_data_path, ans_vocab_data_path, feature_path):\n",
    "        self.sg_data_path = sg_data_path\n",
    "        self.qa_data_path = qa_data_path\n",
    "        self.ans_vocab_data_path = ans_vocab_data_path  \n",
    "        self.feature_path = feature_path\n",
    "        \n",
    "        self.sample_cnt = 0\n",
    "        self.data_sgvqa = []\n",
    "        self._load_dataset()\n",
    "        \n",
    "    def _load_dataset(self):\n",
    "        print('-> Loading filtered dataset ...')\n",
    "        self.ans_vocab_data = sorted(open(self.ans_vocab_data_path, 'r').read().strip().split(\"\\n\"))\n",
    "        sg_data = global_sg_data[:10]\n",
    "        qa_data = global_qa_data[:10]\n",
    "#         sg_data = json.load(open(self.sg_data_path, 'r'))\n",
    "#         qa_data = json.load(open(self.qa_data_path, 'r'))            \n",
    "        \n",
    "        for sample_img, sample_ans in zip(sg_data, qa_data):\n",
    "            if sample_img['image_id'] != sample_ans['id']:\n",
    "                print(\"IDs did not match !\")\n",
    "                continue                \n",
    "                \n",
    "            feature_filename = os.path.join(DST_SG_FEATURES_DATA_FOLDER, \"{}.h5\".format(sample_img['image_id']))\n",
    "            with h5py.File(feature_filename, 'r') as hf:\n",
    "                \n",
    "                g = nx.Graph()\n",
    "                feature_matrix = []\n",
    "                for obj in sample_img['objects']:\n",
    "                    obj_name = obj['names'][0]\n",
    "                    obj_id = obj['object_id']                    \n",
    "                    emb_vec = np.array(hf.get(str(obj_id)))\n",
    "\n",
    "                    g.add_node(obj_id, feature=emb_vec)\n",
    "                    feature_matrix.append(emb_vec)\n",
    "                        \n",
    "                for rel in sample_img['relationships']:\n",
    "                    g.add_edge(rel['subject_id'], rel['object_id'], id=rel['relationship_id'])\n",
    "\n",
    "                adj = nx.adjacency_matrix(g)\n",
    "                # print(adj.todense())\n",
    "                adj = normalize_adj(adj + sp.eye(adj.shape[0]))\n",
    "                sparse_mx = adj.tocoo().astype(np.float32)\n",
    "                # adj = torch.FloatTensor(np.array(adj.todense()))\n",
    "                adj = np.array(adj.todense())        \n",
    "                \n",
    "                # feature_matrix = normalize(np.asarray(feature_matrix))\n",
    "                # feature_matrix = torch.FloatTensor(np.array(feature_matrix.todense()))\n",
    "#                 print(np.array(feature_matrix, np.float32).shape)\n",
    "#                 feature_matrix = torch.FloatTensor(np.array(feature_matrix, np.float32))\n",
    "                \n",
    "                \n",
    "                adj_matrix_per_sample = []    \n",
    "                feature_matrix_per_sample = []\n",
    "                for qa_index, qa in enumerate(sample_ans['qas']):\n",
    "                    if (qa['qas_skip']): continue\n",
    "                    question = qa['question']\n",
    "                    answer = qa['answer'].replace(\".\", \"\").lower()\n",
    "                    # sg = sample_img  \n",
    "                    \n",
    "                    adj_matrix_per_sample.append(adj)\n",
    "                    feature_matrix_per_sample.append(feature_matrix)\n",
    "                \n",
    "                print(len(feature_matrix_per_sample))\n",
    "                print(len(adj_matrix_per_sample))\n",
    "                print(len(feature_matrix_per_sample[0]))\n",
    "                print(len(adj_matrix_per_sample[0]))\n",
    "                print(adj_matrix_per_sample[0].shape)\n",
    "                f = np.array(feature_matrix_per_sample, np.float32)\n",
    "                a = np.array(adj_matrix_per_sample)\n",
    "                print(f.shape)\n",
    "                print(a.shape)\n",
    "                feature_matrix_per_sample = torch.FloatTensor(np.array(feature_matrix_per_sample, np.float32))\n",
    "                adj_matrix_per_sample = torch.FloatTensor(np.array(adj_matrix_per_sample))\n",
    "                \n",
    "                self.data_sgvqa.append({\"question\": question, \"answer\": answer,\n",
    "                                        \"sg_adj\": adj_matrix_per_sample, \"sg_feat\": feature_matrix})\n",
    "                \n",
    "                self.sample_cnt += 1\n",
    "                if (self.sample_cnt > 10): break # todo: remove                       \n",
    "        \n",
    "        print('-> Finished loading data : num. samples -> {}'.format(self.sample_cnt))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.sample_cnt\n",
    "                \n",
    "    def __getitem__(self, index):\n",
    "        if index < self.sample_cnt:\n",
    "            item = self.data_sgvqa[index]\n",
    "        else:\n",
    "            item = self.data_sgvqa[index - self.sample_cnt]\n",
    "        return item\n",
    "\n",
    "    def num_classes(self):\n",
    "        return len(self.ans_vocab_data)\n",
    "\n",
    "#     def vocab_words(self):\n",
    "#         return self.dataset_vqa.vocab_words()\n",
    "\n",
    "#     def vocab_answers(self):\n",
    "#         return self.dataset_vqa.vocab_answers()\n",
    "\n",
    "    def data_loader(self, batch_size=10, num_workers=4, shuffle=False):\n",
    "        return DataLoader(self, \n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=shuffle,\n",
    "                          num_workers=num_workers, \n",
    "                          pin_memory=True)\n",
    "\n",
    "    def split_name(self, testdev=False):\n",
    "        return self.data_sgvqa.split_name(testdev=testdev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Loading filtered dataset ...\n",
      "61\n",
      "61\n",
      "40\n",
      "40\n",
      "(40, 40)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-d8d507c6021a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m vqa_dataloader = VQAVGSimpleDataset(SRC_SG_PATH, SRC_SGQAS_OF_INTEREST_QA_DATA_FILE, SRC_ANSWER_VOCAB_FILE,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                     DST_SG_FEATURES_DATA_FOLDER)\n",
      "\u001b[0;32m<ipython-input-93-b08530c68e70>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sg_data_path, qa_data_path, ans_vocab_data_path, feature_path)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_cnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_sgvqa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_load_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-93-b08530c68e70>\u001b[0m in \u001b[0;36m_load_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj_matrix_per_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj_matrix_per_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                 \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_matrix_per_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m                 \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj_matrix_per_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "vqa_dataloader = VQAVGSimpleDataset(SRC_SG_PATH, SRC_SGQAS_OF_INTEREST_QA_DATA_FILE, SRC_ANSWER_VOCAB_FILE,\n",
    "                                    DST_SG_FEATURES_DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
